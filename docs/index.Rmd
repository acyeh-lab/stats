---
title: "Stats Tutorials in R"
author: "Albert Yeh"
date: "12/17/2023"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: true
    toc_depth: 3
    number_sections: true
    theme: lumen
---
For a great introductory R Workshop on working with and visualizing data analyses, please visit Dr. Andrew Portuguese's site: https://aportugu.github.io/Rworkshop/.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r libraries, include = FALSE}
#install.packages("pwr")
#install.packages("tidyr")
#install.packages("ggplot2")
#install.packages("kableExtra")
#install.packages("WebPower")
#install.packages("powerSurvEpi")
```
# Power Analyses
Power analysis is a critical part of experimental design with the primary purpose of estimating the sample size required to detect an effect of a given size with a given degree of confidence. In other words, it is the probability of detecting an effect, given that the effect is really there. 

Why is it important?  First, a power analysis is a good way of making sure that you have thought through every aspect of the study and the statistical analysis before you start collecting data. This is critical in designing clinical experiments and also in data analyses where you want to gauge if you have enough sample size to conduct a meaningful analysis. There are other uses as well, if say you have only a fixed number of samples available and want to determine what type of effect size you can hope to detect. Second, for any reasonable grant or study proposal, it is absolutely expected that you have thought through this.

## Considerations
To perform most basic power analyses, you need three of the four variables (you can determine the last variable if given the other 3):

1. **Sample size** = This is your "N". Will need to specificy if same for both groups or different. If only 1 value is given, it assumes both groups have at least that sample size.
2. **Effect size** = This represents the magnitude of an experimental outcome. There are different types depending on the statistical test being used.  Most common is "Cohen's d" for t-tests. otherise include "f" for ANOVA, "r" for correlations, and "w" for chi-squared tests. Generally, an effect size of 0.10 is considered small, 0.20-0.30 is medium, and >0.50 is relatively large. Note that there are dozens different measures of effect sizes. Many effect sizes of different types can be converted to other types, as many estimate the separation of two distributions, so are mathematically related. For example, a correlation coefficient can be converted to a Cohen's d and vice versa.
3. **Significance level** = P(Type I error) = probability of finding an effect that is not there. A standard benchmark is to use "0.05".
4. **Power** = 1 - P(Type II error) = probability of finding an effect that is there. A standard benchmark is to use "0.80".

Note that if you change the statistical procedure used to analyze the data, you will most likely have to redo the power analysis, as the procedure is different for t-tests vs. chi-squared vs. regression etc...

**There is NOT a simple formula for determining effect size for every research situation.** The reality it that there are many research situations that are so complex that they almost defy rational power analysis. In most cases, power analysis involves a number of simplifying assumptions, in order to make the problem tractable, and running the power analysis numerous times with different variations to cover all of the contingencies.

## Implementation
Make sure to install the necessary packages first, e.g. `install.packages("pwr")`

```{r library load, echo=TRUE, results='hide'}
library(pwr) # Basic power analysis package
library(WebPower) # Advanced power analysis package - useful for logistic regression
library(powerSurvEpi) # Power analysis package for survival data
library(tidyr) # For data manipulation
library(dplyr) # For data manipulation
library(kableExtra) # For displaying data
library(ggplot2) # For plotting data

```

# Visualizing a Basic Power Analysis for T-tests
For the tutorial below, we will answer the following question: 

**How many patients would I need to detect a difference between the effects of drug "A" and drug "B" on diastolic blood pressure?**

To do this, we will perform power analyses for a range of inputs assuming our analysis will be conduct with a simple t-test (with all of its assumptions).  We will vary the effect sizes (0.2, 0.5, 0.8) and the sample sizes (up to 500) to see what the power calculation holds.  We will use the default significance level of 0.05.

For t-tests, the effect size used is referred to as "Cohen's d" - this is calculated by taking the difference between the means of the two populations divided by the standard deviation (SD). Note that this implies that you do need to have some prior knowledge of how large you expect the difference between the two means to be, so it is helpful to have a range of inputs. In this case, it would involve knowing roughly the SD for diastolic blood pressure in the population being studied as well as an estimated difference in blood pressure for those on drug "A" and those on drug "B". 

*Often times, you need some pilot data to get a rough estimate of these numbers.  Otherwise, you would just have to make your best educated guess based on available information.* Note that you don't necessarily need to know the actual SD of diastolic blood pressure (which happens to be ~10-12 mmHg), but rather, the ratio of the difference between the two expected means to the SD (fraction of SD). Thus, a "Cohen's d" of 0.8 signifies that the mean difference is nearly 1 SD apart. In a real-world-setting, you want to test a range of "Cohen's d", as is done here.

```{r data, echo=TRUE, results='markup'}
# Note this code snippet was adapted from "https://statsthinking21.github.io/statsthinking21-R-site/statistical-power-in-r.html"
# Specify the data
effect_sizes <- c(0.2, 0.5, 0.8) 
sample_sizes = seq(10, 500, 10)

# Create a data frame using the crossing() function which basically creates a grid/matrix including all possible combinations of values
input_df <- crossing(effect_sizes,sample_sizes)

# glimpse() is from the `dplyr` package and is a transposed version of the function print()
glimpse(input_df) 
```

```{r function, echo=TRUE, results='markup'}
# Create a function get the power value and return as a tibble
get_power <- function(df){
  power_result <- pwr.t.test(n=df$sample_sizes, 
                             d=df$effect_sizes,
                             sig.level=0.05,
                             type='two.sample')
  df$power=power_result$power
  return(df)
}

# Run get_power for each combination of effect size and sample size
power_curves <- input_df %>%
  do(get_power(.)) %>%
  mutate(effect_sizes = as.factor(effect_sizes)) 
```

Now we can plot the power curves, using a separate line for each effect size. Note we draw a horizontal reference line at power = 0.8 as this is a commonly used reference point.
```{r plot power output, echo=TRUE, results='markup'}
ggplot(power_curves, 
       aes(x=sample_sizes,
           y=power, 
           linetype=effect_sizes)) + 
  geom_line() + 
  geom_hline(yintercept = 0.8, 
             linetype='dotdash') + theme_bw()
```

As we can see from the graph above, the sample size needed to achieve a power of 0.8 is much higher when the effect size is small (0.2) compared to when the effect size is large (0.8) (N~400 vs. N~20). In this case, "Cohen's d" is being used as a measure of effect size (remember, it is defined as delta means / standard deviation) - basically, the difference between the two expected means as a percentage of the standard deviation. So an effect size of 0.8 suggests that we expect the difference in effect between the two drugs on diastolic blood pressure to be nearly the same as one standard deviation in blood pressure for the overall population, which is a pretty large assumption!

## An Interactive Follow-up
Please visit this site for an interactive version of the above graph: https://acyeh-lab.shinyapps.io/docs/

# Power Analyses - Extension to Other Outcome Measurements
The above case provides a simple example using outcomes from a t-test to conduct a power analysis. There are other common situations that may arise where a different formula is needed for power analysis as outcomes are being measured differently.  

## Effect sizes
Power calculations to determine sample size requires an input for effect size. Different test outcomes calculate effect sizes differently - common situations are shown below, along with the generally accepted "small", "medium", and "large" effect sizes. Note that for more complex outcome measurements (such as for cox-proportional hazards model for survival analysis), there is not a simple "effect size" variable that captures all of the parameters necessary for analysis.
```{r plot types of power anlyses, echo=FALSE, results='markup'}
t_test <- c("Cohen's d", 0.2, 0.5, 0.8)
prop_test <- c("Cohen's h", 0.2, 0.5, 0.8)
chi_sq <- c("Cohen's w", 0.1, 0.3, 0.5)
ANOVA <- c("Cohen's f", 0.1, 0.25, 0.4)
pearson <- c("R (correlation)", 0.1, 0.3, 0.5)
linear_reg <- c("F^2", 0.02, 0.15, 0.35)
logit_reg <- c("Odds ratio", "N/A", "N/A", "N/A")
survival <- c("Hazard ratio", "N/A", "N/A", "N/A")
df<-data.frame(rbind(t_test,prop_test,chi_sq,ANOVA,pearson,linear_reg, logit_reg, survival))
colnames(df) <- c("Effect Size", "Small", "Medium","Large")
row.names(df) <- c("T-test", "Test of proportion","Chi-squared test (X^2)","Analysis of variance (ANOVA)", "Pearson's correlation", "Linear regression", "Logistic regression", "Survival analysis")

df %>%
  kbl() %>%
  kable_styling()
```

## Modeling in R
Common functions included in the package for power calculations are shown below. For more advanced options, please check out the packages themselves.
```{r power analyses commands, echo=FALSE, results='markup'}
t_test <- c("pwr","pwr.t2n.test(n1 = , n2 = , d = , sig.level = , power = )")
prop_test <- c("pwr","pwr.2p2n.test(h = , n1 = , n2 = , sig.level = , power = )")
chi_sq <- c("pwr","pwr.chisq.test(w = , N = , df = , sig.level = , power = )")
ANOVA <- c("pwr","pwr.anova.test(k = , n = , f = , sig.level = , power = )")
pearson <- c("pwr","pwr.r.test(n = , r = , sig.level = , power = )")
linear_reg <- c("pwr","pwr.f2.test(u = , v = , f2 = , sig.level = , power = )")
logit_reg <- c("WebPower","wp.logistic(n = , p0 = , p1 = , alpha = , power = )")
survival <- c("powerSurvEpi","ssizeCT.default(power = , k = , pE = , pC = , RR = , alpha = )")


df<-data.frame(rbind(t_test,prop_test,chi_sq,ANOVA,pearson,linear_reg,logit_reg,survival))
colnames(df) <- c("R package", "Function using corresponding R package")
row.names(df) <- c("T-test", "Test of proportion","Chi-squared test (X^2)","Analysis of variance (ANOVA)", "Pearson's correlation", "Linear regression", "Logistic regression","Survival analysis")

df %>%
  kbl() %>%
  kable_styling()
```

## Linear Regression (General Linear Model) 
Linear regression analysis is used to predict the value of an independent variable based on the value of dependent variable(s). This form of analysis estimates the coefficients of the linear equation, involving one or more independent variables that best predict the value of the dependent variable.

### Finding the Power
If one looks at the power calculation for linear regression, the effect size is noted as "f^2":
$$
  f^2 = \frac{R^2}{1-R^2}
$$
Where R is the correlation coefficient. We also see two other variables we haven't encountered: "u" and "v".  "u" is the number of dependent variables minus 1 (a.k.a. numerator degrees of freedom), where "v" is the sample size minus dependent variables (a.k.a. denominator degrees of freedom).

Let us take an example, where we have f^2, u, v, alpha, and are looking for power:
```{r, echo=TRUE, results='markup'}
# example: k=3 predictors, n=100 observations, R^2 = .1, sig.level = .05
pwr.f2.test(u = 2,
            v = 97,
            f2 = .1/.9,
            sig.level = 0.05,
            power = NULL)

```


### Finding the Sample Size
Now, let's say we are trying to find how many samples we should have if we are given 5 dependent variables, assuming an "f^2" of 0.15 (medium effect size), a desired power of 0.8, and alpha 0.05:

```{r, echo=TRUE, results='markup'}
# example: k=5 predictors, n=Unknown observations, R^2 = .15, sig.level = .05, power=0.80
pwr.f2.test(u = 4,
            v = NULL,
            f2 = .15/.85,
            sig.level = 0.05,
            power = 0.80)

```
In the above situation, "v" is ~68, so our sample size should be approximately 70 to acheive a power of 0.80 at alpha 0.05.

### Finding how many dependent variables we can use
A common situation is when we want to decide in our regression model how many dependent variables we can use - we know that if we try to regress on too many variables in relation to our sample size, we risk "overfitting". When there are too many predictors, the model can start to "learn" the noise in the data instead of the actual underlying relationship. This means it fits the training data very well, including the random fluctuations, but performs poorly on new, unseen data.
```{r, echo=TRUE, results='markup'}
# example: k=Unknown, n=100 observations, R^2 = .15, sig.level = .05, power=0.80
pwr.f2.test(u = NULL,
            v = 100,
            f2 = .15/.85,
            sig.level = 0.05,
            power = 0.80)

```
In the above situation, "u" ~13, meaning that we can use about 13 dependent variables to acheive the desired power of 0.80 at the given alpha (assuming a "medium" effect size of f^2=0.15).

## Chi-squared test
For the chi-square test, the effect size index w is calculated by dividing the chi-square value by the total count in all of the cells and taking the square root. 
$$
  W=\sqrt{\frac{\chi^2}{N}}
$$
Where the formula for calculating the the chi-squared statistics is found by summing the squares of differences between observed and expected cell counts divided by the expected cell count for each cell:
$$
  \chi^2 = \sum_{i=1}^{m}\frac{(O_i-E_i)^2}{E_i}
$$
### Finding the Sample Size
Now, let's say we are trying to find how many samples we should have if we have a medium effect size (Cohen's w = 0.3) for a 2x2 contingency table, using standard parameters power=0.8 and alpha=0.05. We will also need to put in the degrees of freedom, which is calculated by df=(r-1)(c-1). So for a 2x2 contingency table, the degrees of freedom is 1.

```{r, echo=TRUE, results='markup'}
# example: w=0.3 n=Unknown observations, df=1, sig.level = .05, power=0.80
pwr.chisq.test(w=0.3,
               N=NULL,
               df=1,
               sig.level = 0.05,
               power = 0.80)

```
In the above situation, "N"=87, suggesting that we need at least 87 samples to observe the desired effect size for a 2x2 table.


## Logistic Regression 
While a linear regression models continuous outcomes (e.g. blood pressure change), a logistic regression is used to predict a binary outcome (e.g. occurrence of a heart attack), based on prior observations of a data set.

We will use the `WebPower` package to perform our analysis. Unlike the other tests mentioned before, there is not one "effect size" statistic for logistic regression, but power calculation can still be performed if we can estimate the following two statistics instead:

1. p0 Prob(Y=1|X=0): the probability of observing 1 for the outcome variable Y when the predictor X equals 0.

2. p1	Prob(Y=1|X=1): the probability of observing 1 for the outcome variable Y when the predictor X equals 1.

This can sound a bit confusing, but let's consider the following example:

Suppose you are investigating the effect of drug "A" vs. placebo on the occurrence of heart attacks. Let's define the variables as follows:

1. Y (Outcome Variable): Whether a patient experiences a heart attack (1 = yes, 0 = no improvement).
2. X (Predictor Variable): Whether a patient receives the new medication (1 = medication "A", 0 = no medication/placebo).

Then the probabilities above can be thought of as:

1. p0 Prob(Y=1|X=0): The probability of observing an improvement in patients who did not receive the medication (placebo group).
2. p1 Prob(Y=1|X=1): The probability of observing an improvement in patients who received the medication.

In planning the study, you might want to determine the necessary sample size to achieve a desired power for detecting a significant effect of a medication. You would use estimates for p0 and p1 based on previous research or preliminary data. For example, if preliminary studies suggest that 30% of patients improve with no medication (p0 = 0.30) and 50% improve with the medication (p1 = 0.50), you could use wp.logistic to calculate the required sample size to detect this difference with a certain power and at a 0.05 significance level.
```{r, echo=TRUE, results='markup'}
# example:  n=Unknown observations, p0=0.3 p1=0.5, sig.level=.05, power=0.80
wp.logistic(n = NULL, 
            p0 = 0.30, 
            p1 = 0.50, 
            alpha = 0.05,
            power = 0.80,
            family="Bernoulli")
```
We see that using p0=0.30 and p1=0.50, we get an "N"=192, suggesting we should have at least 192 observations.

## Survival Analysis
Here, we will perform a power calculation comparing survival curves between two groups under the Cox Proportional-Hazards Model for clinical trials (can read more elsewhere).  In brief, survival models relate the time that passes, before some event occurs, to one or more covariates that may be associated with that quantity of time. In a proportional hazards model, we assume that th effect of a unit increase in a covariate is multiplicative with respect to the hazard rate. For example, taking a drug may halve one's hazard rate for a stroke occurring.

Of note, in the `powerSurvEpi` package, unlike the other functions that we have studied where you would leave one variable blank, there are separate functions for separate calculations (i.e. for sample size, for power).

For our power calculations, we use the following variables:

1. nE: number of participants in the experimental group.
2. nC: number of participants in the control group.
3. k: ratio between the number of participants in the control and experimental group
4. pE: probability of failure in group E (experimental group) over the maximum time period of the study (t years).
5. pC: probability of failure in group C (control group) over the maximum time period of the study (t years).
6. RR: postulated hazard ratio (HR < 1 signifies a lower hazard and potential benefit).
7. alpha: type I error rate

### Finding the Sample Size
```{r, echo=TRUE, results='markup'}
# example: unknown (output) = sample size (nE and nC); 
# ssizeCT.default(power = , k = , pE = , pC = , RR = , alpha = )
ssizeCT.default(power = 0.8,
                k = 1,
                pE = 0.5,
                pC = 0.8,
                RR = 0.7,
                alpha = 0.05)
```


### Finding the Power
```{r, echo=TRUE, results='markup'}
# example: unknown (output) = power; 
# powerCT.default(nE = , nC = , pE = , pC = , RR = , alpha = )
powerCT.default(nE = 200,
                nC = 200,
                pE = 0.5,
                pC = 0.8,
                RR = 0.7,
                alpha = 0.05)
```




              


