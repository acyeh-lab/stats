---
title: "Stats Tutorials"
author: "Albert Yeh"
date: "12/17/2023"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r libraries, include = FALSE}
#install.packages("pwr")
#install.packages("tidyr")
#install.packages("ggplot2")
```
## Power Analyses

Power analysis is a critical part of experimental design with the primary purpose of estimating the sample size required to detect an effect of a given size with a given degree of confidence. In other words, it is the probability of detecting an effect, given that the effect is really there. 

Why is it important?  First, a power analysis is a good way of making sure that you have thought through every aspect of the study and the statistical analysis before you start collecting data. This is critical in designing clinical experiments and also in data analyses where you want to gauge if you have enough sample size to conduct a meaningful analysis. There are other uses as well, if say you have only a fixed number of samples available and want to determine what type of effect size you can hope to detect.

### Considerations
To perform a power analysis, you need three of the four variables (you can determine the last variable if given the first 3):

1. **Sample size** = This is your "N". Will need to specificy if same for both groups or different. If only 1 value is given, it assumes both groups have at least that sample size.
2. **Effect size** = This represents the magnitude of an experimental outcome. There are different types depending on the statistical test being used.  Most common is "Cohen's d" for t-tests. otherise include "f" for ANOVA, "r" for correlations, and "w" for chi-squared tests. Generally, an effect size of 0.10 is considered small, 0.20-0.30 is medium, and >0.50 is relatively large. Note that there are dozens different measures of effect sizes. Many effect sizes of different types can be converted to other types, as many estimate the separation of two distributions, so are mathematically related. For example, a correlation coefficient can be converted to a Cohen's d and vice versa.
3. **Significance level** = P(Type I error) = probability of finding an effect that is not there. A standard benchmark is to use "0.05".
4. **Power** = 1 - P(Type II error) = probability of finding an effect that is there. A standard benchmark is to use "0.80".

Note that if you change the statistical procedure used to analyze the data, you will most likely have to redo the power analysis, as the procedure is different for t-tests vs. chi-squared vs. regression etc...

### Implementation
We can compute a power analysis using functions from the `pwr` package. The `tidyr` and `dplyr` package will be used to help generate / manipulate data points and `ggplot2` will be used for plotting data. Make sure to install the packages first, e.g. `install.packages("pwr")`
```{r library load, echo=TRUE, results='hide'}
library(pwr)
library(tidyr)
library(ggplot2)
library(dplyr)
```

## Part 1: Visualizing a Basic Power Analysis for T-tests
For the tutorial below, we will answer the following question: 

**How many patients would I need to detect a difference between the effects of drug "A" and drug "B" on diastolic blood pressure?**

To do this, we will perform power analyses for a range of inputs assuming our analysis will be conduct with a simple t-test (with all of its assumptions).  We will vary the effect sizes (0.2, 0.5, 0.8) and the sample sizes (up to 500) to see what the power calculation holds.  We will use the default significance level of 0.05.

For t-tests, the effect size used is referred to as "Cohen's d" - this is calculated by taking the difference between the means of the two populations divided by the standard deviation (SD). Note that this implies that you do need to have some prior knowledge of how large you expect the difference between the two means to be, so it is helpful to have a range of inputs. In this case, it would involve knowing roughly the SD for diastolic blood pressure in the population being studied as well as an estimated difference in blood pressure for those on drug "A" and those on drug "B". 

*Often times, you need some pilot data to get a rough estimate of these numbers.  Otherwise, you would just have to make your best educated guess based on available information.* Note that you don't necessarily need to know the actual SD of diastolic blood pressure (which happens to be ~10-12 mmHg), but rather, the ratio of the difference between the two expected means to the SD (fraction of SD). Thus, a "Cohen's d" of 0.8 signifies that the mean difference is nearly 1 SD apart. In a real-world-setting, you want to test a range of "Cohen's d", as is done here.

```{r data, echo=TRUE, results='markup'}
# Note this code snippet was adapted from "https://statsthinking21.github.io/statsthinking21-R-site/statistical-power-in-r.html"
# Specify the data
effect_sizes <- c(0.2, 0.5, 0.8) 
sample_sizes = seq(10, 500, 10)

# Create a data frame using the crossing() function which basically creates a grid/matrix including all possible combinations of values
input_df <- crossing(effect_sizes,sample_sizes)

# glimpse() is from the `dplyr` package and is a transponsed version of the function print()
glimpse(input_df) 
```

```{r function, echo=TRUE, results='markup'}
# Create a function get the power value and return as a tibble
get_power <- function(df){
  power_result <- pwr.t.test(n=df$sample_sizes, 
                             d=df$effect_sizes,
                             sig.level=0.05,
                             type='two.sample')
  df$power=power_result$power
  return(df)
}

# Run get_power for each combination of effect size and sample size
power_curves <- input_df %>%
  do(get_power(.)) %>%
  mutate(effect_sizes = as.factor(effect_sizes)) 
```

Now we can plot the power curves, using a separate line for each effect size. Note we draw a horizontal reference line at power = 0.8 as this is a commonly used reference point.
```{r plot power output, echo=TRUE, results='markup'}
ggplot(power_curves, 
       aes(x=sample_sizes,
           y=power, 
           linetype=effect_sizes)) + 
  geom_line() + 
  geom_hline(yintercept = 0.8, 
             linetype='dotdash') + theme_bw()
```

As we can see from the graph above, the sample size needed to achieve a power of 0.8 is much higher when the effect size is small (0.2) compared to when the effect size is large (0.8) (N~400 vs. N~20). In this case, "Cohen's d" is being used as a measure of effect size (remember, it is defined as delta means / standard deviation) - basically, the difference between the two expected means as a percentage of the standard deviation. So an effect size of 0.8 suggests that we expect the difference in effect between the two drugs on diastolic blood pressure to be nearly the same as one standard deviation in blood pressure for the overall population, which is a pretty large assumption!


## Part 2: An Interactive Follow-up

We will take a look at this again using an interactive approach, where you can vary the effect size "Cohen's d". For this tutorial, we will enable 2 simultaneous inputs so we can compare two scenarios.

```{r echo = FALSE}
sliderInput("cohens_d",
  label = "Plot 1: Cohen's d (effect size):",
  min = 0,
  max = 2,
  value = 0.2,
  step = 0.05)

sliderInput("cohens_d2",
  label = "Plot 2: Cohen's d:",
  min = 0,
  max = 2,
  value = 0.8,
  step = 0.05)
```

And power caculation
```{r echo = FALSE}
renderPlot({
  effect_sizes <- c(input$cohens_d, input$cohens_d2) 
  sample_sizes = seq(10, 500, 10)
  input_df <- crossing(effect_sizes,sample_sizes)
  power_curves <- input_df %>%
    do(get_power(.)) %>%
    mutate(effect_sizes = as.factor(effect_sizes)) 
  
  ggplot(power_curves, 
       aes(x=sample_sizes,
           y=power, 
           linetype=effect_sizes)) + 
  geom_line() + 
  geom_hline(yintercept = 0.8, 
             linetype='dotdash') + theme_bw()
})
```


